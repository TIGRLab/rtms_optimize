{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0,'../../optimization/rtms_bayesopt/lib/python2.7/site-packages/')\n",
    "sys.path.insert(0,'/KIMEL/tigrlab/projects/jjeyachandra/gmsh-sdk/lib/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nilearn import image as img\n",
    "from nilearn import plotting as plot\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part here will need to be generalized and taken to external scripts to compute the \"centroid\" voxel/vertex. For now we use a Naive volumetric centroid based on voxels (roughly equivalent to computing spatial centroid in FEM). \n",
    "\n",
    "Alternative we could find a surface-based centroid which is based on shortest paired-path on a mesh-derived graph. Both procedures can be abstracted from the parameter space forming routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get parcels\n",
    "ribbon_dir = '../../data/sub-CMH090/ribbon/'\n",
    "t1 = '../../data/simnibs_output/m2m_sub-CMH090/T1fs_nu_conform.nii.gz'\n",
    "L_ribbons = sorted([os.path.join(ribbon_dir,f) for f in os.listdir(ribbon_dir) if '.L.network' in f])\n",
    "R_ribbons = sorted([os.path.join(ribbon_dir,f) for f in os.listdir(ribbon_dir) if '.R.network' in f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 0\n",
    "r1 = img.math_img('a+b', a=L_ribbons[ind], b=R_ribbons[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.view_img(r1,bg_img=t1,symmetric_cmap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parcel 4 of Control Network A on Left Hemisphere as an example\n",
    "L_img = img.load_img(L_ribbons[ind])\n",
    "r_data = L_img.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get image centroid (left side)\n",
    "x,y,z = np.where(r_data == 4)\n",
    "mu_x,mu_y,mu_z = x.mean(), y.mean(), z.mean()\n",
    "\n",
    "#Round values into integer for visualization\n",
    "vx,vy,vz = int(np.round(mu_x)), int(np.round(mu_y)), int(np.round(mu_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write into r_data\n",
    "r_data[vx-1:vx+1,vy-1:vy+1,vz-1:vz+1] = 9000\n",
    "\n",
    "#Make into NIFTI1\n",
    "roi_img = nib.Nifti1Image(r_data,r1.affine,r1.header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.view_img(roi_img,bg_img=t1,symmetric_cmap=False,cmap='ocean_hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vx,vy,vz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nib.save(roi_img,'./testing.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the centroid coordinate, apply the affine transformation. Then project to closest head voxel (using gmsh), then display in voxel space using reverse affine transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gmsh\n",
    "gmsh.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msh_file = '../../data/simnibs_output/sub-CMH090.msh'\n",
    "gmsh.open(msh_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load head vertices\n",
    "surf_head = (2,5)\n",
    "head_node_tag, head_node_coord, head_node_param = gmsh.model.mesh.getNodes(surf_head[0],surf_head[1])\n",
    "head_node_tag = np.array(head_node_tag)\n",
    "head_node_coord = np.array(head_node_coord).reshape((len(head_node_coord)//3,3))\n",
    "\n",
    "#Load head elements\n",
    "head_tag, head_el, head_tri = gmsh.model.mesh.getElements(dim=2,tag=5)\n",
    "head_tri = np.array(head_tri[0]).reshape((len(head_tri[0])//3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affine transform the candidate coordinate\n",
    "centroid_vox = np.array([mu_x,mu_y,mu_z,1],dtype=np.float32)\n",
    "aff = r1.affine\n",
    "centroid_coord = np.dot(aff,centroid_vox)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Euclidean distance from centroid\n",
    "eudist = np.linalg.norm(head_node_coord - centroid_coord,axis=1)\n",
    "min_ind = np.argmin(eudist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_node_coord[min_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using closest head vertex coordinate <code> head_node_coord[min_ind] </code>, define the parameteric surface by a simple Euclidean distance metric (rather overestimate parametric surface than under using geodesic). \n",
    "\n",
    "Using vertex subset, compute average normalized normal of surrouding faces, then push outward. This defines the spatial positioning parameteric mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all head vertices within Euclidean sphere of head coordinate\n",
    "#in mm\n",
    "head_eudist = np.linalg.norm(head_node_coord - head_node_coord[min_ind],axis=1)\n",
    "search_rad= 25\n",
    "search_inds = np.where(head_eudist < search_rad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up algorithm\n",
    "#Step 1: Sort the vertex list (doesn't actually matter unless using binary tree)\n",
    "vert_list = head_node_tag[search_inds]\n",
    "vert_coords = head_node_coord[search_inds]\n",
    "vert_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit(parallel=True)\n",
    "def get_relevant_triangles(verts, triangles):\n",
    "    '''\n",
    "    From an array of vertices and triangles. Get triangles that contain at least one vertex\n",
    "    Arguments:\n",
    "        verts                                 1-D array of vertexIDs\n",
    "        triangles                             (Nx3) array of triangles, where each column is a vertex\n",
    "    Output:\n",
    "        t_arr                                 Nx1 Boolean array where indices correspond to triangles\n",
    "                                              True if triangle contains at least one vertex from list\n",
    "    '''\n",
    "    \n",
    "    t_arr = np.zeros((triangles.shape[0]),dtype=np.int64)\n",
    "    \n",
    "    for t in numba.prange(0,triangles.shape[0]):\n",
    "        for c in np.arange(0,3):\n",
    "            for v in verts:\n",
    "                \n",
    "                if triangles[t][c] == v:\n",
    "                    t_arr[t] = 1\n",
    "                    break\n",
    "            if t_arr[t] == 1:\n",
    "                break\n",
    "\n",
    "    return t_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get an array with relevant triangles\n",
    "start = timer()\n",
    "t_arr = get_relevant_triangles(vert_list,head_tri)\n",
    "stop = timer()\n",
    "print(stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset the original triangle array\n",
    "t_rel = np.where(t_arr > 0)\n",
    "rel_trigs = head_tri[t_rel[0],:]\n",
    "\n",
    "#Get val --> index array mapping (no dicts in numba lel)\n",
    "u_val = np.unique(rel_trigs)\n",
    "u_ind = np.arange(0,u_val.shape[0])\n",
    "\n",
    "#Create mapping \n",
    "sort_map = {v:i for v,i in zip(u_val,u_ind)}\n",
    "\n",
    "#Map triangle nodes to normalized values based on sort index\n",
    "map_func = lambda x: sort_map[x]\n",
    "vmap_func = np.vectorize(map_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply map to triangles then get associated coordinates (already sorted)\n",
    "mapped_trigs = vmap_func(rel_trigs)\n",
    "rtrig_verts = np.where(np.isin(head_node_tag,u_val))\n",
    "rvert_coords = head_node_coord[rtrig_verts,:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def unitize_arr(arr):\n",
    "    '''\n",
    "    Normalize array row-wise\n",
    "    '''\n",
    "    \n",
    "    narr = np.zeros((arr.shape[0],3),dtype=np.float64)\n",
    "    for i in np.arange(0,arr.shape[0]):\n",
    "        narr[i] = arr[i,:]/np.linalg.norm(arr[i,:])\n",
    "        \n",
    "    return narr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def cross(a,b):\n",
    "    '''\n",
    "    Compute cross product between two vectors (latest numpy method)\n",
    "    Arguments:\n",
    "        a,b                    A single vector \n",
    "        \n",
    "    Output\n",
    "        Cross product\n",
    "    '''\n",
    "    #Output array\n",
    "    out = np.zeros(3,dtype=np.float64)\n",
    "    \n",
    "    out[0] = a[1]*b[2]\n",
    "    tmp = a[2]*b[1]\n",
    "    out[0] -= tmp\n",
    "    \n",
    "    out[1] = a[2]*b[0]\n",
    "    tmp = a[0]*b[2]\n",
    "    out[1] -= tmp\n",
    "    \n",
    "    out[2] = a[0]*b[1]\n",
    "    tmp = a[1]*b[0]\n",
    "    out[2] -= tmp\n",
    "    \n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def get_vert_norms(trigs, coords):\n",
    "    '''\n",
    "    Compute vertex normals using cumulative normalization trick\n",
    "    Arguments:\n",
    "        trigs                                Array of triangles with normalized values (1 --> size(unique(trigs)))\n",
    "        coords                               Array of coordinates (vals in trigs corresponds to ind in coords)\n",
    "    Output:\n",
    "        norm_arr                             Array of norm vectors\n",
    "    '''\n",
    "    \n",
    "    cnorm_arr = np.zeros((coords.shape[0],3),dtype=np.float64)\n",
    "    for i in np.arange(0,trigs.shape[0]):\n",
    "        \n",
    "        iv1 = trigs[i,0]\n",
    "        iv2 = trigs[i,1]\n",
    "        iv3 = trigs[i,2]\n",
    "        \n",
    "        v1 = coords[iv1,:]\n",
    "        v2 = coords[iv2,:]\n",
    "        v3 = coords[iv3,:]\n",
    "        \n",
    "        c = cross(v2-v1,v3-v1)\n",
    "        \n",
    "        cnorm_arr[iv1,:] += c\n",
    "        cnorm_arr[iv2,:] += c\n",
    "        cnorm_arr[iv3,:] += c\n",
    "        \n",
    "    \n",
    "    #Run normalization routine\n",
    "    norm_arr = unitize_arr(cnorm_arr)\n",
    "    return norm_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute vertex normals\n",
    "start = timer()\n",
    "norm_arr = get_vert_norms(mapped_trigs,rvert_coords)\n",
    "stop = timer()\n",
    "print(stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get indices of norms to use (from original vertex list)\n",
    "norm_vinds = np.where(np.isin(vert_list,u_val))[0]\n",
    "norm_varr = norm_arr[norm_vinds]\n",
    "print(vert_list.shape,norm_varr.shape, vert_coords.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply vertex-wise dilation (1 unit = 1mm), use (c)mm \n",
    "c = 5\n",
    "dil_coords = vert_coords + c*np.mean(norm_varr,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get subset of triangles for vertex subset\n",
    "@numba.njit(parallel=True)\n",
    "def get_subset_triangles(verts, triangles):\n",
    "    '''\n",
    "    From an array of vertices and triangles. Get triangles that contain all vertices\n",
    "    Arguments:\n",
    "        verts                                 1-D array of vertexIDs\n",
    "        triangles                             (Nx3) array of triangles, where each column is a vertex\n",
    "    Output:\n",
    "        t_arr                                 Nx1 Boolean array where indices correspond to triangles\n",
    "                                              True if all 3 vertices of triangle found in verts\n",
    "    '''\n",
    "    \n",
    "    t_arr = np.zeros((triangles.shape[0]),dtype=np.int64)\n",
    "    \n",
    "    for t in numba.prange(0,triangles.shape[0]):\n",
    "        for c in np.arange(0,3):\n",
    "            for v in verts:\n",
    "                \n",
    "                if triangles[t][c] == v:\n",
    "                    t_arr[t] += 1\n",
    "                    break\n",
    "                    \n",
    "        if t_arr[t] == 3:\n",
    "            t_arr[t] = 1\n",
    "        else:\n",
    "            t_arr[t] = 0\n",
    "\n",
    "    return t_arr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get face information for parametric surface (for visualization)\n",
    "start = timer()\n",
    "dil_faces_ind = get_subset_triangles(vert_list,rel_trigs)\n",
    "stop = timer()\n",
    "print(stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vars for parameteric surface mesh, shift vert_list/trigs by max to prevent nodal overlap\n",
    "dil_faces = rel_trigs[np.where(dil_faces_ind)].flatten(order='C') + vert_list.max()\n",
    "dil_faces = list(dil_faces)\n",
    "dil_verts = vert_list + vert_list.max() \n",
    "dil_coords = dil_coords.flatten()\n",
    "print(len(dil_faces),dil_verts.shape,dil_coords.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate parameteric surface mesh and save\n",
    "gmsh.initialize()\n",
    "gmsh.model.add('param_surf')\n",
    "tag = gmsh.model.addDiscreteEntity(2,2001)\n",
    "gmsh.model.mesh.setNodes(2,tag,nodeTags=dil_verts,coord=dil_coords)\n",
    "gmsh.model.mesh.setElements(2,tag,[2],\n",
    "                            elementTags=[range(1,len(dil_faces)//3 + 1)],\n",
    "                            nodeTags=[dil_faces])\n",
    "gmsh.write('../../output/param_surf.msh')\n",
    "gmsh.finalize() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write sampling coordinates into numpy binary\n",
    "dil_coords.tofile('../../output/param_surf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write normal vertex to surface\n",
    "v_norm = np.mean(norm_varr,axis=0)\n",
    "v_norm.tofile('../../output/norm_varr')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
