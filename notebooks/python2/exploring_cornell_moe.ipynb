{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of Cornell-MOE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom package environment\n",
    "sys.path.insert(0,'/KIMEL/tigrlab/projects/jjeyachandra/gmsh-sdk/lib/')\n",
    "sys.path.insert(0,'/home/jjeyachandra/simnibs_2.1.2/miniconda2/envs/simnibs_env/lib/python2.7/site-packages')\n",
    "sys.path.insert(0,'/home/jjeyachandra/simnibs_2.1.2/Python_modules/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add cornell library\n",
    "sys.path.insert(0, '/projects/jjeyachandra/Cornell-MOE/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples import synthetic_functions\n",
    "\n",
    "#Define an objective function using their example func\n",
    "objective_func = synthetic_functions.Hartmann3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moe.optimal_learning.python.cpp_wrappers.domain import TensorProductDomain as cTensorProductDomain\n",
    "from moe.optimal_learning.python.python_version.domain import TensorProductDomain\n",
    "from moe.optimal_learning.python.geometry_utils import ClosedInterval\n",
    "\n",
    "#Make an n-dimensional domain containing closed intervals\n",
    "search_domain = TensorProductDomain([ClosedInterval(bound[0],bound[1]) for bound in objective_func._search_domain])\n",
    "cpp_search_domain = cTensorProductDomain([ClosedInterval(bound[0],bound[1]) for bound in objective_func._search_domain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00127755  0.64758549  0.51351195]\n",
      " [ 0.39874241  0.28674006  0.84441703]\n",
      " [ 0.75829803  0.8475034   0.05003889]]\n"
     ]
    }
   ],
   "source": [
    "#Array to fill in with initial points\n",
    "init_pts = np.zeros( (objective_func._num_init_pts, objective_func._dim) )\n",
    "init_pts[:, :objective_func._dim] = search_domain.generate_uniform_random_points_in_domain(\n",
    "                                            objective_func._num_init_pts)\n",
    "print(init_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -1.62839345e+01  -1.03606579e+01  -9.12807754e-03]\n"
     ]
    }
   ],
   "source": [
    "#Evaluate at init pts using noise-less sampling\n",
    "observations = np.array([objective_func.evaluate_true(p).sum() for p in init_pts])\n",
    "print(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'points_sampled': [{'point': [0.0012775507773065131,\n",
       "    0.64758549275119104,\n",
       "    0.51351194737167627],\n",
       "   'value': [-16.283934540806573],\n",
       "   'value_var': 0.0},\n",
       "  {'point': [0.39874241402977839, 0.28674005964724192, 0.84441703184238515],\n",
       "   'value': [-10.360657862424077],\n",
       "   'value_var': 0.0},\n",
       "  {'point': [0.75829802875039043, 0.84750340439225014, 0.050038886074943847],\n",
       "   'value': [-0.0091280775395779015],\n",
       "   'value_var': 0.0}]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from moe.optimal_learning.python.data_containers import HistoricalData, SamplePoint\n",
    "\n",
    "#Store observations into a data_container and display\n",
    "init_data = HistoricalData(dim = objective_func._dim, num_derivatives=0)\n",
    "init_data.append_sample_points([(c,v,0) for c,v in zip(init_pts,observations)])\n",
    "init_data.json_payload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the log-likelihood minimization of $\\mathcal{GP}$ model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moe.optimal_learning.python.cpp_wrappers.log_likelihood_mcmc import GaussianProcessLogLikelihoodMCMC\n",
    "from moe.optimal_learning.python.default_priors import DefaultPrior\n",
    "#Priors for (?)\n",
    "# l : D length scales\n",
    "# mu : len(y) number of means\n",
    "# v : number of noise values\n",
    "# t : covariance amplitude\n",
    "# Dimensions = D + (len(y)) + t\n",
    "# Noise Terms = len(y)\n",
    "prior = DefaultPrior(n_dims=objective_func._dim + 2,num_noise=1)\n",
    "gp_ll = GaussianProcessLogLikelihoodMCMC(historical_data=init_data,derivatives = [],\n",
    "                                        prior=prior, chain_length=1000, burnin_steps=2000,\n",
    "                                        n_hypers=2**4, noisy=False)\n",
    "## n_hypers is a lower-limit on the number of MCMC chains to use\n",
    "gp_ll.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moe.optimal_learning.python.python_version.optimization import GradientDescentOptimizer, GradientDescentParameters\n",
    "from moe.optimal_learning.python.cpp_wrappers.optimization import GradientDescentOptimizer as cGDOpt\n",
    "from moe.optimal_learning.python.cpp_wrappers.optimization import GradientDescentParameters as cGDParams\n",
    "sgd_params = cGDParams(num_multistarts=1, \n",
    "                       max_num_steps=6,\n",
    "                       max_num_restarts=1,\n",
    "                       num_steps_averaged=3,\n",
    "                       gamma=0.0,\n",
    "                       pre_mult=1.0,\n",
    "                       max_relative_change=0.2,\n",
    "                       tolerance=1.0e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moe.optimal_learning.python.cpp_wrappers.expected_improvement import ExpectedImprovement\n",
    "from moe.optimal_learning.python.cpp_wrappers.expected_improvement import multistart_expected_improvement_optimization as meio\n",
    "\n",
    "def gen_sample_from_qei(gp, search_domain,sgd_params, num_samples, num_mc=1e4, lhc_iter=2e4):\n",
    "    \n",
    "    qEI = ExpectedImprovement(gaussian_process=gp, num_mc_iterations=num_mc)\n",
    "    optimizer = cGDOpt(search_domain, qEI, sgd_params, int(lhc_iter))\n",
    "    points_to_sample = []\n",
    "    ei_list = []\n",
    "    \n",
    "    points_to_sample.append(meio(optimizer, None, num_samples,use_gpu=False,which_gpu=0,\n",
    "                                max_num_threads=8))\n",
    "    \n",
    "    \n",
    "    qEI.set_current_point(points_to_sample[0])\n",
    "    ei_list.append(qEI.compute_expected_improvement())\n",
    "    return points_to_sample[0], ei_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.87497362126\n"
     ]
    }
   ],
   "source": [
    "#Sample points using SGD maximization of q-EI\n",
    "points_to_sample, ei = gen_sample_from_qei(gp_ll.models[0],cpp_search_domain,sgd_params,8,num_mc=2**10)\n",
    "print(ei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KEY: Evaluate the suggested points -- should parallelize and maximize number of evaluated points at a time\n",
    "sampled_points = [objective_func.evaluate_true(x).sum() for x in points_to_sample]\n",
    "\n",
    "#evidence tuples\n",
    "evidence_tup = [ (c,v,0) for c,v in zip(points_to_sample,sampled_points)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update the model\n",
    "gp_ll.add_sampled_points(evidence_tup)\n",
    "gp_ll.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
