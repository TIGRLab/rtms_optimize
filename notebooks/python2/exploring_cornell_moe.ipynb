{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of Cornell-MOE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom package environment\n",
    "sys.path.insert(0,'/KIMEL/tigrlab/projects/jjeyachandra/gmsh-sdk/lib/')\n",
    "sys.path.insert(0,'/home/jjeyachandra/simnibs_2.1.2/miniconda2/envs/simnibs_env/lib/python2.7/site-packages')\n",
    "sys.path.insert(0,'/home/jjeyachandra/simnibs_2.1.2/Python_modules/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add cornell library\n",
    "sys.path.insert(0, '/projects/jjeyachandra/Cornell-MOE/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples import synthetic_functions\n",
    "\n",
    "#Define an objective function using their example func\n",
    "objective_func = synthetic_functions.Rosenbrock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moe.optimal_learning.python.cpp_wrappers.domain import TensorProductDomain as cTensorProductDomain\n",
    "from moe.optimal_learning.python.python_version.domain import TensorProductDomain\n",
    "from moe.optimal_learning.python.geometry_utils import ClosedInterval\n",
    "\n",
    "#Make an n-dimensional domain containing closed intervals\n",
    "search_domain = TensorProductDomain([ClosedInterval(bound[0],bound[1]) for bound in objective_func._search_domain])\n",
    "cpp_search_domain = cTensorProductDomain([ClosedInterval(bound[0],bound[1]) for bound in objective_func._search_domain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.4702256  -0.3150478 ]\n",
      " [-0.07813419 -0.76792158]\n",
      " [-1.55459385  1.64201219]]\n"
     ]
    }
   ],
   "source": [
    "#Array to fill in with initial points\n",
    "init_pts = np.zeros( (objective_func._num_init_pts, objective_func._dim) )\n",
    "init_pts[:, :objective_func._dim] = search_domain.generate_uniform_random_points_in_domain(\n",
    "                                            objective_func._num_init_pts)\n",
    "print(init_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 613.58137425   61.07408108   66.54968349]\n"
     ]
    }
   ],
   "source": [
    "#Evaluate at init pts using noise-less sampling\n",
    "observations = np.array([objective_func.evaluate_true(p)[0] for p in init_pts])\n",
    "print(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moe.optimal_learning.python.data_containers import HistoricalData, SamplePoint\n",
    "\n",
    "#Store observations into a data_container and display\n",
    "init_data = HistoricalData(dim = objective_func._dim, num_derivatives=0)\n",
    "init_data.append_sample_points([SamplePoint(pt, o, 0.0) for pt,o in zip(init_pts,observations)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[_BaseSamplePoint(point=array([ 1.4702256, -0.3150478]), value=array([ 613.58137425]), noise_variance=0.0),\n",
      " _BaseSamplePoint(point=array([-0.07813419, -0.76792158]), value=array([ 61.07408108]), noise_variance=0.0),\n",
      " _BaseSamplePoint(point=array([-1.55459385,  1.64201219]), value=array([ 66.54968349]), noise_variance=0.0)]\n"
     ]
    }
   ],
   "source": [
    "print(init_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the log-likelihood minimization of $\\mathcal{GP}$ model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moe.optimal_learning.python.cpp_wrappers.log_likelihood_mcmc import GaussianProcessLogLikelihoodMCMC\n",
    "from moe.optimal_learning.python.default_priors import DefaultPrior\n",
    "#Priors for (?)\n",
    "# l : D length scales\n",
    "# mu : len(y) number of means\n",
    "# v : number of noise values\n",
    "# t : covariance amplitude\n",
    "# Dimensions = D + (len(y)) + t\n",
    "# Noise Terms = len(y)\n",
    "prior = DefaultPrior(n_dims=objective_func._dim + 2,num_noise=1)\n",
    "gp_ll = GaussianProcessLogLikelihoodMCMC(historical_data=init_data,derivatives = [],\n",
    "                                        prior=prior, chain_length=1000, burnin_steps=2000,\n",
    "                                        n_hypers=2**4, noisy=False, rng=20)\n",
    "## n_hypers is a lower-limit on the number of MCMC chains to use\n",
    "gp_ll.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moe.optimal_learning.python.python_version.optimization import GradientDescentOptimizer, GradientDescentParameters\n",
    "from moe.optimal_learning.python.cpp_wrappers.optimization import GradientDescentOptimizer as cGDOpt\n",
    "from moe.optimal_learning.python.cpp_wrappers.optimization import GradientDescentParameters as cGDParams\n",
    "sgd_params = cGDParams(num_multistarts=200, \n",
    "                       max_num_steps=50,\n",
    "                       max_num_restarts=2,\n",
    "                       num_steps_averaged=4,\n",
    "                       gamma=0.7,\n",
    "                       pre_mult=1.0,\n",
    "                       max_relative_change=0.5,\n",
    "                       tolerance=1.0e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moe.optimal_learning.python.cpp_wrappers.expected_improvement import ExpectedImprovement\n",
    "from moe.optimal_learning.python.cpp_wrappers.expected_improvement import multistart_expected_improvement_optimization as meio\n",
    "\n",
    "def gen_sample_from_qei(gp,search_domain,sgd_params,num_samples, num_mc=1e4, lhc_iter=2e4):\n",
    "    \n",
    "    qEI = ExpectedImprovement(gaussian_process=gp, num_mc_iterations=int(num_mc))\n",
    "    optimizer = cGDOpt(search_domain, qEI, sgd_params, int(lhc_iter))\n",
    "    points_to_sample = []\n",
    "    ei_list = []\n",
    "    \n",
    "    points_to_sample.append(meio(optimizer, None, num_samples,use_gpu=False,which_gpu=0,\n",
    "                                max_num_threads=8))\n",
    "    \n",
    "    \n",
    "    qEI.set_current_point(points_to_sample[0])\n",
    "    ei_list.append(qEI.compute_expected_improvement())\n",
    "    return points_to_sample[0], ei_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop until convergence criterion/satisfactory value reached (test to make sure it works)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, display\n",
    "num_iters = 50\n",
    "optimum = objective_func._min_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective_func.evaluate_true(np.array([1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SingularMatrixException",
     "evalue": "SingularMatrixException: 27 x 27 matrix is singular; 17-th leading minor is not SPD.\nCovariance matrix (K) singular. Check for duplicate points_sampled (with 0 noise) and/or extreme hyperparameter values. void optimal_learning::GaussianProcess::RecomputeDerivedVariables(bool) (/mnt/tigrlab/projects/jjeyachandra/Cornell-MOE/moe/optimal_learning/cpp/gpp_math.cpp: 495)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSingularMatrixException\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-569f175f08fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#Add to GPLogLikelihoodMaximization and re-train new model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mgp_ll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_sampled_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevidence_tup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mgp_ll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projects/jjeyachandra/Cornell-MOE/moe/optimal_learning/python/cpp_wrappers/log_likelihood_mcmc.pyc\u001b[0m in \u001b[0;36madd_sampled_points\u001b[0;34m(self, sampled_points)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_models\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_sampled_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/projects/jjeyachandra/Cornell-MOE/moe/optimal_learning/python/cpp_wrappers/gaussian_process.pyc\u001b[0m in \u001b[0;36madd_sampled_points\u001b[0;34m(self, sampled_points)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mcpp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcppify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_historical_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoints_sampled_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_sampled_prev\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# cpp_utils.cppify(self._historical_data.points_sampled_noise_variance[num_sampled_prev:]),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m             \u001b[0mnum_to_add\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m         )\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSingularMatrixException\u001b[0m: SingularMatrixException: 27 x 27 matrix is singular; 17-th leading minor is not SPD.\nCovariance matrix (K) singular. Check for duplicate points_sampled (with 0 noise) and/or extreme hyperparameter values. void optimal_learning::GaussianProcess::RecomputeDerivedVariables(bool) (/mnt/tigrlab/projects/jjeyachandra/Cornell-MOE/moe/optimal_learning/cpp/gpp_math.cpp: 495)"
     ]
    }
   ],
   "source": [
    "#Generate optimal points to sample\n",
    "for i in np.arange(0,20):   \n",
    "    \n",
    "    points_to_sample,ei = gen_sample_from_qei(gp_ll.models[0], cpp_search_domain, sgd_params=sgd_params,\n",
    "                                              num_samples=8,num_mc=2**10)\n",
    "    #Evaluate underlying objective function at these points\n",
    "    sampled_points = [objective_func.evaluate_true(x)[0] for x in points_to_sample]\n",
    "\n",
    "    #Build list of sampled points\n",
    "    evidence_tup = [ SamplePoint(c,v,0.0) for c,v in zip(points_to_sample, sampled_points)] \n",
    "\n",
    "    #Add to GPLogLikelihoodMaximization and re-train new model\n",
    "    gp_ll.add_sampled_points(evidence_tup)\n",
    "    gp_ll.train()\n",
    "\n",
    "    #Pull model being trained and compute errors\n",
    "    gp = gp_ll.models[1]\n",
    "    min_point = np.argmin(gp._points_sampled_value)\n",
    "    min_val = np.min(gp._points_sampled_value)\n",
    "    best_coord = gp.get_historical_data_copy().points_sampled[min_point,:]\n",
    "    error = np.abs(min_val - optimum)\n",
    "\n",
    "    #Print out useful information\n",
    "    clear_output()\n",
    "    print('Recommended Points:')\n",
    "    print(points_to_sample)\n",
    "    print('Expected Improvement: {}'.format(ei))\n",
    "    print('Current Best:')\n",
    "    print('Coord:', best_coord)\n",
    "    print('f(x*)=', min_val)\n",
    "    print('Error:', error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stuck in local optima for some reason??????"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
