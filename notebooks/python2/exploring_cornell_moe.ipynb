{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of Cornell-MOE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom package environment\n",
    "sys.path.insert(0,'/KIMEL/tigrlab/projects/jjeyachandra/gmsh-sdk/lib/')\n",
    "sys.path.insert(0,'/home/jjeyachandra/simnibs_2.1.2/miniconda2/envs/simnibs_env/lib/python2.7/site-packages')\n",
    "sys.path.insert(0,'/home/jjeyachandra/simnibs_2.1.2/Python_modules/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add cornell library\n",
    "sys.path.insert(0, '/projects/jjeyachandra/Cornell-MOE/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples import synthetic_functions\n",
    "\n",
    "#Define an objective function using their example func\n",
    "objective_func = synthetic_functions.Rosenbrock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moe.optimal_learning.python.cpp_wrappers.domain import TensorProductDomain as cTensorProductDomain\n",
    "from moe.optimal_learning.python.python_version.domain import TensorProductDomain\n",
    "from moe.optimal_learning.python.geometry_utils import ClosedInterval\n",
    "\n",
    "#Make an n-dimensional domain containing closed intervals\n",
    "search_domain = TensorProductDomain([ClosedInterval(bound[0],bound[1]) for bound in objective_func._search_domain])\n",
    "cpp_search_domain = cTensorProductDomain([ClosedInterval(bound[0],bound[1]) for bound in objective_func._search_domain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.21814212 -1.21306508]\n",
      " [-1.57848778  1.23585204]\n",
      " [ 1.47324507  0.56030307]]\n"
     ]
    }
   ],
   "source": [
    "#Array to fill in with initial points\n",
    "init_pts = np.zeros( (objective_func._num_init_pts, objective_func._dim) )\n",
    "init_pts[:, :objective_func._dim] = search_domain.generate_uniform_random_points_in_domain(\n",
    "                                            objective_func._num_init_pts)\n",
    "print(init_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 160.40798135  164.34483926  259.48161212]\n"
     ]
    }
   ],
   "source": [
    "#Evaluate at init pts using noise-less sampling\n",
    "observations = np.array([objective_func.evaluate_true(p)[0] for p in init_pts])\n",
    "print(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moe.optimal_learning.python.data_containers import HistoricalData, SamplePoint\n",
    "\n",
    "#Store observations into a data_container and display\n",
    "init_data = HistoricalData(dim = objective_func._dim, num_derivatives=0)\n",
    "init_data.append_sample_points([SamplePoint(pt, o, 0.0) for pt,o in zip(init_pts,observations)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[_BaseSamplePoint(point=array([-0.21814212, -1.21306508]), value=array([ 160.40798135]), noise_variance=0.0),\n",
      " _BaseSamplePoint(point=array([-1.57848778,  1.23585204]), value=array([ 164.34483926]), noise_variance=0.0),\n",
      " _BaseSamplePoint(point=array([ 1.47324507,  0.56030307]), value=array([ 259.48161212]), noise_variance=0.0)]\n"
     ]
    }
   ],
   "source": [
    "print(init_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the log-likelihood minimization of $\\mathcal{GP}$ model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moe.optimal_learning.python.cpp_wrappers.log_likelihood_mcmc import GaussianProcessLogLikelihoodMCMC\n",
    "from moe.optimal_learning.python.default_priors import DefaultPrior\n",
    "#Priors for (?)\n",
    "# l : D length scales\n",
    "# mu : len(y) number of means\n",
    "# v : number of noise values\n",
    "# t : covariance amplitude\n",
    "# Dimensions = D + (len(y)) + t\n",
    "# Noise Terms = len(y)\n",
    "prior = DefaultPrior(n_dims=objective_func._dim + 2,num_noise=1)\n",
    "gp_ll = GaussianProcessLogLikelihoodMCMC(historical_data=init_data,derivatives = [],\n",
    "                                        prior=prior, chain_length=1000, burnin_steps=2000,\n",
    "                                        n_hypers=2**4, noisy=False, rng=20)\n",
    "## n_hypers is a lower-limit on the number of MCMC chains to use\n",
    "gp_ll.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moe.optimal_learning.python.python_version.optimization import GradientDescentOptimizer, GradientDescentParameters\n",
    "from moe.optimal_learning.python.cpp_wrappers.optimization import GradientDescentOptimizer as cGDOpt\n",
    "from moe.optimal_learning.python.cpp_wrappers.optimization import GradientDescentParameters as cGDParams\n",
    "sgd_params = cGDParams(num_multistarts=200, \n",
    "                       max_num_steps=50,\n",
    "                       max_num_restarts=2,\n",
    "                       num_steps_averaged=4,\n",
    "                       gamma=0.7,\n",
    "                       pre_mult=1.0,\n",
    "                       max_relative_change=0.5,\n",
    "                       tolerance=1.0e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moe.optimal_learning.python.cpp_wrappers.expected_improvement import ExpectedImprovement\n",
    "from moe.optimal_learning.python.cpp_wrappers.expected_improvement import multistart_expected_improvement_optimization as meio\n",
    "\n",
    "def gen_sample_from_qei(gp,search_domain,sgd_params,num_samples, num_mc=1e4, lhc_iter=2e4):\n",
    "    \n",
    "    qEI = ExpectedImprovement(gaussian_process=gp, num_mc_iterations=int(num_mc))\n",
    "    optimizer = cGDOpt(search_domain, qEI, sgd_params, int(lhc_iter))\n",
    "    points_to_sample = []\n",
    "    ei_list = []\n",
    "    \n",
    "    points_to_sample.append(meio(optimizer, None, num_samples,use_gpu=False,which_gpu=0,\n",
    "                                max_num_threads=8))\n",
    "    \n",
    "    \n",
    "    qEI.set_current_point(points_to_sample[0])\n",
    "    ei_list.append(qEI.compute_expected_improvement())\n",
    "    return points_to_sample[0], ei_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop until convergence criterion/satisfactory value reached (test to make sure it works)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, display\n",
    "num_iters = 50\n",
    "optimum = objective_func._min_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective_func.evaluate_true(np.array([1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Points:\n",
      "[[-1.03304009  1.97110143]\n",
      " [ 1.00949206 -1.82886066]\n",
      " [-0.64550096 -1.11914942]\n",
      " [ 1.13600046 -0.57620053]\n",
      " [ 1.67549987 -0.33240937]\n",
      " [ 1.68728083  1.91037955]\n",
      " [-1.50009097  0.4554011 ]\n",
      " [ 0.47477821 -1.36310434]]\n",
      "Expected Improvement: 0.0\n",
      "Current Best:\n",
      "('Coord:', array([-1.50911494,  2.        ]))\n",
      "('f(x*)=', 13.992281274890406)\n",
      "('Error:', 13.992281274890406)\n"
     ]
    }
   ],
   "source": [
    "#Generate optimal points to sample\n",
    "for i in np.arange(0,20):   \n",
    "    \n",
    "    points_to_sample,ei = gen_sample_from_qei(gp_ll.models[0], cpp_search_domain, sgd_params=sgd_params,\n",
    "                                              num_samples=8,num_mc=2**10)\n",
    "    #Evaluate underlying objective function at these points\n",
    "    sampled_points = [objective_func.evaluate_true(x)[0] for x in points_to_sample]\n",
    "\n",
    "    #Build list of sampled points\n",
    "    evidence_tup = [ SamplePoint(c,v,0.0) for c,v in zip(points_to_sample, sampled_points)] \n",
    "\n",
    "    #Add to GPLogLikelihoodMaximization and re-train new model\n",
    "    gp_ll.add_sampled_points(evidence_tup)\n",
    "    gp_ll.train()\n",
    "\n",
    "    #Pull model being trained and compute errors\n",
    "    gp = gp_ll.models[1]\n",
    "    min_point = np.argmin(gp._points_sampled_value)\n",
    "    min_val = np.min(gp._points_sampled_value)\n",
    "    best_coord = gp.get_historical_data_copy().points_sampled[min_point,:]\n",
    "    error = np.abs(min_val - optimum)\n",
    "\n",
    "    #Print out useful information\n",
    "    clear_output()\n",
    "    print('Recommended Points:')\n",
    "    print(points_to_sample)\n",
    "    print('Expected Improvement: {}'.format(ei))\n",
    "    print('Current Best:')\n",
    "    print('Coord:', best_coord)\n",
    "    print('f(x*)=', min_val)\n",
    "    print('Error:', error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stuck in local optima for some reason??????"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
